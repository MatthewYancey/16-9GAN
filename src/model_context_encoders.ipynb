{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_context_encoders.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNECquMro1CylWVntafR99i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewYancey/GANime/blob/master/src/model_context_encoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuQRtKwu0HN0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfxMXJnq_kzW"
      },
      "source": [
        "# GANime - Context Encoder\n",
        "This notebook applies the context encoder paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bouI0_AzCRZy"
      },
      "source": [
        "## Imports and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "885wpFfz2zLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd49e5d-9978-42ea-82af-c9ac5effe060"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "sys.path.append('/content/gdrive/MyDrive/repos/GANime/src')\n",
        "from helper_functions import apply_mask, apply_padding, apply_comp, apply_scale, load_checkpoint, checkpoint\n",
        "from data_loaders import create_dataloaders\n",
        "from networks_context_encoders import Generator, Discriminator, weights_init"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw3URZEO3MZm"
      },
      "source": [
        "# network parameters\n",
        "BATCH_SIZE = 15\n",
        "DATASET_SIZE = 100000\n",
        "N_BATCHES = DATASET_SIZE // BATCH_SIZE\n",
        "N_GPU = 1\n",
        "N_WORKERS = 1\n",
        "N_EPOCHS = 100\n",
        "LEARNING_RATE = 0.0002\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "# image\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 456\n",
        "SINGLE_SIDE = 57\n",
        "\n",
        "# tensorboard\n",
        "TRAIN_REFERENCE_INDEX = 200\n",
        "VAL_REFERENCE_INDEX = 100\n",
        "TEST_REFERENCE_INDEX = 20\n",
        "\n",
        "# cost weights\n",
        "WEIGHT_DECAY = 0.05\n",
        "\n",
        "# directories\n",
        "ZIP_PATH_TRAIN = '/content/gdrive/My Drive/repos/GANime/data_out/train.zip'\n",
        "IMG_DIR_TRAIN = '/content/frames/train/'\n",
        "ZIP_PATH_VAL = '/content/gdrive/My Drive/repos/GANime/data_out/validate.zip'\n",
        "IMG_DIR_VAL = '/content/frames/validate/'\n",
        "ZIP_PATH_TEST = '/content/gdrive/My Drive/repos/GANime/data_out/test.zip'\n",
        "IMG_DIR_TEST = '/content/frames/test/'\n",
        "LOG_DIR = '/content/gdrive/My Drive/repos/GANime/data_out/logs/model_gans/'\n",
        "PREV_CHECKPOINT = '/content/gdrive/My Drive/repos/GANime/data_out/logs/model_gans/checkpoint.pt' # set to none to not load and create a new log folder\n",
        "# PREV_CHECKPOINT = None # set to none to not load and create a new log folder"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}