{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_context_encoders.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN3DK3vDznYTKSUeR5BUS5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewYancey/GANime/blob/master/src/model_context_encoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfxMXJnq_kzW"
      },
      "source": [
        "# GANime - Context Encoder\n",
        "This notebook applies the context encoder paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bouI0_AzCRZy"
      },
      "source": [
        "## Imports and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "885wpFfz2zLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd871f2-c36e-46ac-81c0-20b136bea70d"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "sys.path.append('/content/gdrive/MyDrive/repos/GANime/src')\n",
        "from helper_functions import apply_mask, apply_padding, apply_comp, apply_scale, load_checkpoint, checkpoint, gpu_memory\n",
        "from data_loaders import create_dataloaders\n",
        "from networks_context_encoders import Generator, Discriminator, weights_init"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw3URZEO3MZm"
      },
      "source": [
        "# network parameters\n",
        "BATCH_SIZE = 15\n",
        "DATASET_SIZE = 1000000\n",
        "N_BATCHES = DATASET_SIZE // BATCH_SIZE\n",
        "N_GPU = 1\n",
        "N_WORKERS = 1\n",
        "N_EPOCHS = 100\n",
        "GEN_LEARNING_RATE = 0.001\n",
        "DISC_LEARNING_RATE = 0.0001\n",
        "ALPHA_WEIGHT = 0.9\n",
        "DROPOUT_RATE = 0.1\n",
        "\n",
        "# image\n",
        "IMG_HEIGHT = 288\n",
        "IMG_WIDTH = 512\n",
        "SINGLE_SIDE = 64\n",
        "\n",
        "# tensorboard\n",
        "# TRAIN_REFERENCE_INDEX = 200\n",
        "# VAL_REFERENCE_INDEX = 100\n",
        "TEST_REFERENCES = [2800, 8000, 17850, 3000]\n",
        "\n",
        "# cost weights\n",
        "WEIGHT_DECAY = 0.05\n",
        "\n",
        "# directories\n",
        "ZIP_PATH_TRAIN = '/content/gdrive/My Drive/repos/GANime/data_out/pokemon/train.zip'\n",
        "IMG_DIR_TRAIN = '/content/frames/train/'\n",
        "ZIP_PATH_VAL = '/content/gdrive/My Drive/repos/GANime/data_out/pokemon/validate.zip'\n",
        "IMG_DIR_VAL = '/content/frames/validate/'\n",
        "ZIP_PATH_TEST = '/content/gdrive/My Drive/repos/GANime/data_out/pokemon/test.zip'\n",
        "IMG_DIR_TEST = '/content/frames/test/'\n",
        "LOG_DIR = '/content/gdrive/My Drive/repos/GANime/data_out/logs/model_context_encoders/'\n",
        "# PREV_CHECKPOINT = '/content/gdrive/My Drive/repos/GANime/data_out/logs/model_context_encoders/checkpoint.pt' # set to none to not load and create a new log folder\n",
        "PREV_CHECKPOINT = None # set to none to not load and create a new log folder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzips images\n",
        "if os.path.exists(IMG_DIR_TRAIN) == False:\n",
        "    shutil.unpack_archive(ZIP_PATH_TRAIN, IMG_DIR_TRAIN, 'zip')\n",
        "    shutil.unpack_archive(ZIP_PATH_VAL, IMG_DIR_VAL, 'zip')\n",
        "    shutil.unpack_archive(ZIP_PATH_TEST, IMG_DIR_TEST, 'zip')"
      ],
      "metadata": {
        "id": "lM3AjT6K7gHK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sets what device to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and N_GPU > 0) else \"cpu\")\n",
        "print(f'Device: {device}')\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0tVJnSA72ht",
        "outputId": "c8571499-804f-40f5-bab0-0d27bf76963b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-ed9a6da3-733c-fcb8-5afb-96e175173c35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_train, dataloader_val, dataloader_test = create_dataloaders(BATCH_SIZE, N_WORKERS, IMG_DIR_TRAIN, IMG_DIR_VAL, IMG_DIR_TEST, DATASET_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi4wVo_075gD",
        "outputId": "a74cdb37-9138-48fd-df9a-8d01a3a10cab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset\n",
            "Number of images: 429979\n",
            "Size of dataset: 429979\n",
            "Validation Dataset\n",
            "Number of images: 122851\n",
            "Size of dataset: 122851\n",
            "Testing Dataset\n",
            "Number of images: 61426\n",
            "Size of dataset: 61426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen = Generator(IMG_WIDTH, SINGLE_SIDE).to(device)\n",
        "gen.apply(weights_init)\n",
        "disc = Discriminator().to(device)\n",
        "disc.apply(weights_init)\n",
        "gpu_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu0EwLAf78i2",
        "outputId": "9c5a8d74-0a56-4db9-fce0-8ba450e257a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocated memory: 2.3949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_bce = nn.BCELoss()\n",
        "loss_mse = nn.MSELoss()\n",
        "optimizer_gen = optim.Adam(gen.parameters(), lr=GEN_LEARNING_RATE, betas=(0.5, 0.9))\n",
        "optimizer_disc = optim.Adam(disc.parameters(), lr=DISC_LEARNING_RATE, betas=(0.5, 0.9), weight_decay=WEIGHT_DECAY)"
      ],
      "metadata": {
        "id": "EQTRkGdX-vtX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loads the checkpoint\n",
        "gen, optimizer_gen, disc, optimizer_disc, batch_counter = load_checkpoint(PREV_CHECKPOINT, LOG_DIR, gen, optimizer_gen, disc, optimizer_disc)\n",
        "gpu_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrn_SZo4_m_-",
        "outputId": "49db26de-7df8-4c5c-e04c-a0945310e1d3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders removed\n",
            "Allocated memory: 2.3949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "    # gets data for the generator\n",
        "    for i, batch in enumerate(dataloader_train, 0):\n",
        "        batch = batch.to(device)\n",
        "        #############################\n",
        "        # Discriminator\n",
        "        #############################\n",
        "        disc.zero_grad()\n",
        "        disc_output = disc(batch)\n",
        "        disc_loss_real = loss_bce(disc_output, torch.ones(disc_output.shape[0], 1).cuda())\n",
        "        disc_accuracy = (disc_output.round() == torch.ones(disc_output.shape[0], 1).cuda()).sum()\n",
        "        disc_loss_real.backward()\n",
        "\n",
        "        # apply mask to the images\n",
        "        batch_mask = batch.clone()\n",
        "        batch_mask = apply_mask(batch_mask, IMG_WIDTH, SINGLE_SIDE)\n",
        "\n",
        "        # passes fake images to feed the discriminator\n",
        "        gen_output = gen(batch_mask)\n",
        "        gen_output = apply_comp(batch, gen_output, IMG_WIDTH, SINGLE_SIDE)\n",
        "        disc_output = disc(gen_output)\n",
        "\n",
        "        # calcualtes accuracy and loss on the fake images\n",
        "        disc_accuracy += (disc_output.round() == torch.zeros(disc_output.shape[0], 1).cuda()).sum()\n",
        "        disc_accuracy = disc_accuracy / (BATCH_SIZE * 2)\n",
        "        disc_loss_fake = loss_bce(disc_output, torch.zeros(disc_output.shape[0], 1).to(device))\n",
        "        disc_loss_fake.backward()\n",
        "\n",
        "        # optimized the discriminator\n",
        "        disc_loss = (disc_loss_real + disc_loss_fake) / 200  # scale the loss between 0 and 1\n",
        "        optimizer_disc.step()\n",
        "\n",
        "        #############################\n",
        "        # Generater\n",
        "        #############################\n",
        "        gen.zero_grad()\n",
        "        gen_output = gen(batch_mask)\n",
        "\n",
        "        # combines the sides from the generator with the 4:3\n",
        "        gen_output = apply_comp(batch, gen_output, IMG_WIDTH, SINGLE_SIDE)\n",
        "        disc_output = disc(gen_output)\n",
        "        \n",
        "        # calculates the loss\n",
        "        gen_train_loss_l2 = loss_mse(gen_output, batch)\n",
        "        gen_train_loss_bce = loss_bce(disc_output, torch.ones(disc_output.shape[0], 1).cuda())\n",
        "        gen_train_loss = gen_train_loss_l2*ALPHA_WEIGHT + gen_train_loss_bce*(1-ALPHA_WEIGHT)\n",
        "\n",
        "        # error and optimize\n",
        "        gen_train_loss.backward()\n",
        "        optimizer_gen.step()\n",
        "\n",
        "        # prints the status and checkpoints every so often\n",
        "        if i % 10 == 0:\n",
        "            # gets the validation loss\n",
        "            batch = next(iter(dataloader_val))\n",
        "            batch = batch.to(device)\n",
        "            batch_mask = batch.clone()\n",
        "            batch_mask = apply_mask(batch_mask, IMG_WIDTH, SINGLE_SIDE)\n",
        "            with torch.no_grad():\n",
        "                gen_output = gen(batch_mask)\n",
        "            gen_output = apply_comp(batch, gen_output, IMG_WIDTH, SINGLE_SIDE)\n",
        "\n",
        "            # calcuates the validation loss\n",
        "            disc_output = disc(gen_output)\n",
        "            gen_val_loss_bce = loss_bce(disc_output, torch.ones(disc_output.shape[0], 1).cuda())\n",
        "            gen_val_loss_l2 = loss_mse(gen_output, batch)\n",
        "            gen_val_loss = gen_val_loss_l2*ALPHA_WEIGHT + gen_val_loss_bce*(1-ALPHA_WEIGHT)\n",
        "\n",
        "            print(f'Epoch: {epoch}/{N_EPOCHS}, Batch: {i}/{N_BATCHES}, Total Images {batch_counter * BATCH_SIZE}, Gen Train Loss: {gen_train_loss:.4f}, Gen Val Loss: {gen_val_loss:.4f}, Disc Accuracy: {disc_accuracy:.4f}, CUDA Memory: {(torch.cuda.memory_allocated() / 10**9):.4f}')\n",
        "\n",
        "            if i % 200 == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "                checkpoint(i,\n",
        "                           batch_counter,\n",
        "                           disc_loss.item(),\n",
        "                           disc_accuracy,\n",
        "                           gen_train_loss.item(),\n",
        "                           gen_train_loss_l2.item(),\n",
        "                           gen_val_loss.item(),\n",
        "                           gen_val_loss_l2.item(),\n",
        "                           LOG_DIR,\n",
        "                           gen,\n",
        "                           optimizer_gen,\n",
        "                           disc,\n",
        "                           optimizer_disc,\n",
        "                           dataloader_test,\n",
        "                           TEST_REFERENCES,\n",
        "                           IMG_HEIGHT,\n",
        "                           IMG_WIDTH,\n",
        "                           SINGLE_SIDE)\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        batch_counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCycYGQeAHRV",
        "outputId": "33e1a4c0-966b-4084-af82-f80d05727532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/100, Batch: 0/66666, Total Images 0, Gen Train Loss: 0.1812, Gen Val Loss: 0.1725, Disc Accuracy: 0.5333, CUDA Memory: 10.1336\n",
            "Saving reference images\n",
            "Saving reference images\n",
            "Saving reference images\n",
            "Saving reference images\n",
            "Saving checkpoint at new epoch\n",
            "Saved to tensorboard\n",
            "Epoch: 0/100, Batch: 10/66666, Total Images 150, Gen Train Loss: 0.1586, Gen Val Loss: 0.1311, Disc Accuracy: 0.3000, CUDA Memory: 10.4727\n",
            "Epoch: 0/100, Batch: 20/66666, Total Images 300, Gen Train Loss: 0.1784, Gen Val Loss: 0.1699, Disc Accuracy: 0.6333, CUDA Memory: 10.5529\n",
            "Epoch: 0/100, Batch: 30/66666, Total Images 450, Gen Train Loss: 0.1559, Gen Val Loss: 0.1562, Disc Accuracy: 0.5000, CUDA Memory: 10.5529\n",
            "Epoch: 0/100, Batch: 40/66666, Total Images 600, Gen Train Loss: 0.1480, Gen Val Loss: 0.1683, Disc Accuracy: 0.5000, CUDA Memory: 10.5529\n",
            "Epoch: 0/100, Batch: 50/66666, Total Images 750, Gen Train Loss: 0.1794, Gen Val Loss: 0.1553, Disc Accuracy: 0.7333, CUDA Memory: 10.5248\n",
            "Epoch: 0/100, Batch: 60/66666, Total Images 900, Gen Train Loss: 0.1689, Gen Val Loss: 0.1881, Disc Accuracy: 0.8000, CUDA Memory: 10.5258\n",
            "Epoch: 0/100, Batch: 70/66666, Total Images 1050, Gen Train Loss: 0.1626, Gen Val Loss: 0.1635, Disc Accuracy: 0.6667, CUDA Memory: 10.5248\n",
            "Epoch: 0/100, Batch: 80/66666, Total Images 1200, Gen Train Loss: 0.1486, Gen Val Loss: 0.1562, Disc Accuracy: 0.6667, CUDA Memory: 10.5518\n",
            "Epoch: 0/100, Batch: 90/66666, Total Images 1350, Gen Train Loss: 0.1440, Gen Val Loss: 0.1646, Disc Accuracy: 0.7333, CUDA Memory: 10.5513\n",
            "Epoch: 0/100, Batch: 100/66666, Total Images 1500, Gen Train Loss: 0.1694, Gen Val Loss: 0.1758, Disc Accuracy: 0.7000, CUDA Memory: 10.4717\n",
            "Epoch: 0/100, Batch: 110/66666, Total Images 1650, Gen Train Loss: 0.1662, Gen Val Loss: 0.1588, Disc Accuracy: 0.7000, CUDA Memory: 10.4717\n",
            "Epoch: 0/100, Batch: 120/66666, Total Images 1800, Gen Train Loss: 0.1563, Gen Val Loss: 0.1359, Disc Accuracy: 0.6667, CUDA Memory: 10.4717\n",
            "Epoch: 0/100, Batch: 130/66666, Total Images 1950, Gen Train Loss: 0.1370, Gen Val Loss: 0.1306, Disc Accuracy: 0.5000, CUDA Memory: 10.4712\n",
            "Epoch: 0/100, Batch: 140/66666, Total Images 2100, Gen Train Loss: 0.1556, Gen Val Loss: 0.1617, Disc Accuracy: 0.6667, CUDA Memory: 10.5518\n",
            "Epoch: 0/100, Batch: 150/66666, Total Images 2250, Gen Train Loss: 0.1530, Gen Val Loss: 0.1549, Disc Accuracy: 0.6000, CUDA Memory: 10.5524\n",
            "Epoch: 0/100, Batch: 160/66666, Total Images 2400, Gen Train Loss: 0.1511, Gen Val Loss: 0.1517, Disc Accuracy: 0.7000, CUDA Memory: 10.4717\n",
            "Epoch: 0/100, Batch: 170/66666, Total Images 2550, Gen Train Loss: 0.1576, Gen Val Loss: 0.1662, Disc Accuracy: 0.4333, CUDA Memory: 10.4722\n",
            "Epoch: 0/100, Batch: 180/66666, Total Images 2700, Gen Train Loss: 0.1685, Gen Val Loss: 0.1497, Disc Accuracy: 0.7000, CUDA Memory: 10.5518\n",
            "Epoch: 0/100, Batch: 190/66666, Total Images 2850, Gen Train Loss: 0.1736, Gen Val Loss: 0.1500, Disc Accuracy: 0.8000, CUDA Memory: 10.5524\n",
            "Epoch: 0/100, Batch: 200/66666, Total Images 3000, Gen Train Loss: 0.1356, Gen Val Loss: 0.1412, Disc Accuracy: 0.5333, CUDA Memory: 10.5518\n",
            "Saved to tensorboard\n",
            "Epoch: 0/100, Batch: 210/66666, Total Images 3150, Gen Train Loss: 0.1543, Gen Val Loss: 0.1438, Disc Accuracy: 0.5000, CUDA Memory: 10.5524\n",
            "Epoch: 0/100, Batch: 220/66666, Total Images 3300, Gen Train Loss: 0.1492, Gen Val Loss: 0.1356, Disc Accuracy: 0.4333, CUDA Memory: 10.5518\n",
            "Epoch: 0/100, Batch: 230/66666, Total Images 3450, Gen Train Loss: 0.1615, Gen Val Loss: 0.1628, Disc Accuracy: 0.7667, CUDA Memory: 10.5524\n",
            "Epoch: 0/100, Batch: 240/66666, Total Images 3600, Gen Train Loss: 0.1428, Gen Val Loss: 0.1489, Disc Accuracy: 0.6667, CUDA Memory: 10.5529\n",
            "Epoch: 0/100, Batch: 250/66666, Total Images 3750, Gen Train Loss: 0.1715, Gen Val Loss: 0.1491, Disc Accuracy: 0.8000, CUDA Memory: 10.5509\n",
            "Epoch: 0/100, Batch: 260/66666, Total Images 3900, Gen Train Loss: 0.1748, Gen Val Loss: 0.1405, Disc Accuracy: 0.6000, CUDA Memory: 10.5514\n",
            "Epoch: 0/100, Batch: 270/66666, Total Images 4050, Gen Train Loss: 0.1784, Gen Val Loss: 0.1675, Disc Accuracy: 0.8667, CUDA Memory: 10.5524\n",
            "Epoch: 0/100, Batch: 280/66666, Total Images 4200, Gen Train Loss: 0.1748, Gen Val Loss: 0.1454, Disc Accuracy: 0.7000, CUDA Memory: 10.5524\n",
            "Epoch: 0/100, Batch: 290/66666, Total Images 4350, Gen Train Loss: 0.1826, Gen Val Loss: 0.1700, Disc Accuracy: 0.7667, CUDA Memory: 10.5514\n",
            "Epoch: 0/100, Batch: 300/66666, Total Images 4500, Gen Train Loss: 0.1604, Gen Val Loss: 0.1536, Disc Accuracy: 0.8000, CUDA Memory: 10.5518\n",
            "Epoch: 0/100, Batch: 310/66666, Total Images 4650, Gen Train Loss: 0.1827, Gen Val Loss: 0.1434, Disc Accuracy: 0.8333, CUDA Memory: 10.5529\n",
            "Epoch: 0/100, Batch: 320/66666, Total Images 4800, Gen Train Loss: 0.1564, Gen Val Loss: 0.1253, Disc Accuracy: 0.8667, CUDA Memory: 10.4738\n",
            "Epoch: 0/100, Batch: 330/66666, Total Images 4950, Gen Train Loss: 0.1584, Gen Val Loss: 0.1577, Disc Accuracy: 0.5000, CUDA Memory: 10.4728\n",
            "Epoch: 0/100, Batch: 340/66666, Total Images 5100, Gen Train Loss: 0.1654, Gen Val Loss: 0.1518, Disc Accuracy: 0.9000, CUDA Memory: 10.5269\n",
            "Epoch: 0/100, Batch: 350/66666, Total Images 5250, Gen Train Loss: 0.1677, Gen Val Loss: 0.1651, Disc Accuracy: 0.9000, CUDA Memory: 10.5524\n",
            "Epoch: 0/100, Batch: 360/66666, Total Images 5400, Gen Train Loss: 0.1563, Gen Val Loss: 0.1479, Disc Accuracy: 0.9333, CUDA Memory: 10.5509\n",
            "Epoch: 0/100, Batch: 370/66666, Total Images 5550, Gen Train Loss: 0.1810, Gen Val Loss: 0.1397, Disc Accuracy: 0.9667, CUDA Memory: 10.5508\n",
            "Epoch: 0/100, Batch: 380/66666, Total Images 5700, Gen Train Loss: 0.1718, Gen Val Loss: 0.1388, Disc Accuracy: 0.9333, CUDA Memory: 10.5524\n",
            "Epoch: 0/100, Batch: 390/66666, Total Images 5850, Gen Train Loss: 0.1664, Gen Val Loss: 0.1536, Disc Accuracy: 0.9667, CUDA Memory: 10.4727\n",
            "Epoch: 0/100, Batch: 400/66666, Total Images 6000, Gen Train Loss: 0.1698, Gen Val Loss: 0.1488, Disc Accuracy: 0.9000, CUDA Memory: 10.5518\n",
            "Saved to tensorboard\n",
            "Epoch: 0/100, Batch: 410/66666, Total Images 6150, Gen Train Loss: 0.1937, Gen Val Loss: 0.1538, Disc Accuracy: 0.9333, CUDA Memory: 10.4733\n",
            "Epoch: 0/100, Batch: 420/66666, Total Images 6300, Gen Train Loss: 0.1842, Gen Val Loss: 0.1516, Disc Accuracy: 0.9333, CUDA Memory: 10.4738\n",
            "Epoch: 0/100, Batch: 430/66666, Total Images 6450, Gen Train Loss: 0.2161, Gen Val Loss: 0.1782, Disc Accuracy: 1.0000, CUDA Memory: 10.5529\n",
            "Epoch: 0/100, Batch: 440/66666, Total Images 6600, Gen Train Loss: 0.2157, Gen Val Loss: 0.1722, Disc Accuracy: 1.0000, CUDA Memory: 10.5518\n",
            "Epoch: 0/100, Batch: 450/66666, Total Images 6750, Gen Train Loss: 0.2252, Gen Val Loss: 0.1983, Disc Accuracy: 1.0000, CUDA Memory: 10.5518\n",
            "Epoch: 0/100, Batch: 460/66666, Total Images 6900, Gen Train Loss: 0.2679, Gen Val Loss: 0.2475, Disc Accuracy: 1.0000, CUDA Memory: 10.5254\n",
            "Epoch: 0/100, Batch: 470/66666, Total Images 7050, Gen Train Loss: 0.2832, Gen Val Loss: 0.2250, Disc Accuracy: 1.0000, CUDA Memory: 10.4722\n",
            "Epoch: 0/100, Batch: 480/66666, Total Images 7200, Gen Train Loss: 0.2761, Gen Val Loss: 0.1942, Disc Accuracy: 1.0000, CUDA Memory: 10.4727\n",
            "Epoch: 0/100, Batch: 490/66666, Total Images 7350, Gen Train Loss: 0.2684, Gen Val Loss: 0.2808, Disc Accuracy: 1.0000, CUDA Memory: 10.4738\n",
            "Epoch: 0/100, Batch: 500/66666, Total Images 7500, Gen Train Loss: 0.2818, Gen Val Loss: 0.2441, Disc Accuracy: 1.0000, CUDA Memory: 10.5524\n",
            "Epoch: 0/100, Batch: 510/66666, Total Images 7650, Gen Train Loss: 0.2369, Gen Val Loss: 0.1885, Disc Accuracy: 1.0000, CUDA Memory: 10.5514\n",
            "Epoch: 0/100, Batch: 520/66666, Total Images 7800, Gen Train Loss: 0.3106, Gen Val Loss: 0.2789, Disc Accuracy: 1.0000, CUDA Memory: 10.5248\n",
            "Epoch: 0/100, Batch: 530/66666, Total Images 7950, Gen Train Loss: 0.3096, Gen Val Loss: 0.2810, Disc Accuracy: 1.0000, CUDA Memory: 10.4738\n",
            "Epoch: 0/100, Batch: 540/66666, Total Images 8100, Gen Train Loss: 0.3262, Gen Val Loss: 0.2995, Disc Accuracy: 1.0000, CUDA Memory: 10.4728\n",
            "Epoch: 0/100, Batch: 550/66666, Total Images 8250, Gen Train Loss: 0.3595, Gen Val Loss: 0.2895, Disc Accuracy: 1.0000, CUDA Memory: 10.5259\n",
            "Epoch: 0/100, Batch: 560/66666, Total Images 8400, Gen Train Loss: 0.3444, Gen Val Loss: 0.3260, Disc Accuracy: 1.0000, CUDA Memory: 10.5514\n",
            "Epoch: 0/100, Batch: 570/66666, Total Images 8550, Gen Train Loss: 0.3236, Gen Val Loss: 0.2931, Disc Accuracy: 1.0000, CUDA Memory: 10.5513\n",
            "Epoch: 0/100, Batch: 580/66666, Total Images 8700, Gen Train Loss: 0.3389, Gen Val Loss: 0.3329, Disc Accuracy: 1.0000, CUDA Memory: 10.4993\n",
            "Epoch: 0/100, Batch: 590/66666, Total Images 8850, Gen Train Loss: 0.3465, Gen Val Loss: 0.3316, Disc Accuracy: 1.0000, CUDA Memory: 10.4717\n",
            "Epoch: 0/100, Batch: 600/66666, Total Images 9000, Gen Train Loss: 0.3494, Gen Val Loss: 0.3157, Disc Accuracy: 1.0000, CUDA Memory: 10.4727\n"
          ]
        }
      ]
    }
  ]
}