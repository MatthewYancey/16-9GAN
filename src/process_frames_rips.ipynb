{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "process_frames.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewYancey/GANime/blob/master/src/process_frames_rips.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv_Hsd_xSby-"
      },
      "source": [
        "# Data Processing\n",
        "\n",
        "This notebook takes the video files in a folder and saves the individual frames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jTVB-DOJsfR"
      },
      "source": [
        "## Imports and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8U3uYZgT7cJ"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import zipfile"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oizpkeLYSn-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa5d4ad-0650-4b3b-aeba-ded871774e47"
      },
      "source": [
        "# parameters\n",
        "drive.mount('/content/gdrive')\n",
        "VIDEO_PATH = '/content/gdrive/My Drive/repos/GANime/data_raw/pokemon/'\n",
        "TEST_PATH = '/content/gdrive/My Drive/repos/GANime/data_raw/pokemon/'\n",
        "FRAME_PATH = '/content/frames/'\n",
        "ZIP_FOLDER = '/content/gdrive/My Drive/repos/GANime/data_out/'\n",
        "\n",
        "IMAGE_WIDTH = 512\n",
        "IMAGE_HEIGHT = 288\n",
        "SINGLE_SIDE = 64 # number of pixels to block out for training\n",
        "\n",
        "FRAME_SECONDS_SKIP = 10\n",
        "SKIP_SECONDS_BEGINNING = 0\n",
        "SKIP_SECONDS_END = 0\n",
        "\n",
        "TRAIN_SPLIT = 0.70\n",
        "VAL_SPLIT = 0.20\n",
        "TEST_SPLIT = 0.10"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8J3fsm2KDFb"
      },
      "source": [
        "## Video loop and frame saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3NUGPIiUCKz"
      },
      "source": [
        "def save_frames(video_list, zip_path, four_by_three=False):\n",
        "\n",
        "    try:\n",
        "        shutil.rmtree(FRAME_PATH)\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "    \n",
        "    os.mkdir(FRAME_PATH)\n",
        "\n",
        "    frame_count = 0\n",
        "    for f in video_list:\n",
        "        print(f)\n",
        "        vidcap = cv2.VideoCapture(f)\n",
        "        video_length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT) / 24)\n",
        "        success, image = vidcap.read()\n",
        "\n",
        "        # loops through and save the frames\n",
        "        while success:\n",
        "            current_frame = vidcap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "\n",
        "            # skips the intro, outtro, and every 24 frames\n",
        "            if four_by_three:\n",
        "                if current_frame % (FRAME_SECONDS_SKIP * 24) == 0:                    \n",
        "                    # resizes and save the frame\n",
        "                    image = cv2.resize(image, (IMAGE_WIDTH - (2 * SINGLE_SIDE), IMAGE_HEIGHT))\n",
        "                    cv2.imwrite(f'{FRAME_PATH}{frame_count}.jpg', image)\n",
        "                    frame_count += 1\n",
        "\n",
        "            else:\n",
        "                if (current_frame >= (SKIP_SECONDS_BEGINNING * 24) and current_frame <= (video_length - SKIP_SECONDS_END) * 24 and current_frame % (FRAME_SECONDS_SKIP * 24) == 0):\n",
        "                    # resizes and save the frame\n",
        "                    image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
        "                    cv2.imwrite(f'{FRAME_PATH}{frame_count}.jpg', image)\n",
        "                    frame_count += 1\n",
        "\n",
        "            # loop to the next frame\n",
        "            success, image = vidcap.read()\n",
        "                \n",
        "        print(f'Number of images saved: {frame_count}')\n",
        "\n",
        "    shutil.make_archive(zip_path, 'zip', FRAME_PATH)\n",
        "    print(f'Saved zip {zip_path}')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keeps one video out for testing\n",
        "# video_files = glob.glob(VIDEO_PATH + '*')\n",
        "video_files = glob.glob('/content/*')\n",
        "video_files.sort()\n",
        "# train_files = video_files[:int(len(video_files) * TRAIN_SPLIT):]\n",
        "# video_files = [v for v in video_files if v not in train_files]\n",
        "# val_files = video_files[:int(len(video_files) * (VAL_SPLIT / (VAL_SPLIT + TEST_SPLIT)))]\n",
        "# video_files = [v for v in video_files if v not in val_files]\n",
        "# test_files = video_files\n",
        "\n",
        "# print(f'Train videos: {len(train_files)}')\n",
        "# print(f'Validate videos: {len(val_files)}')\n",
        "# print(f'Test videos: {len(test_files)}')\n",
        "\n",
        "# # saves a train an test zip file\n",
        "# save_frames(val_files, ZIP_FOLDER + 'validate')\n",
        "# save_frames(train_files, ZIP_FOLDER + 'train')\n",
        "# save_frames(test_files, ZIP_FOLDER + 'test')\n",
        "print(video_files)\n",
        "save_frames(video_files, ZIP_FOLDER + 'train')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "fGLdyQHBsseH",
        "outputId": "95b5783a-3171-4dc8-a87c-245f328f827e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/frames', '/content/gdrive', '/content/mkv test.m4v', '/content/sample_data']\n",
            "/content/frames\n",
            "Number of images saved: 0\n",
            "/content/gdrive\n",
            "Number of images saved: 0\n",
            "/content/mkv test.m4v\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-12acdb2716bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# save_frames(test_files, ZIP_FOLDER + 'test')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0msave_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZIP_FOLDER\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-f82a97fe695e>\u001b[0m in \u001b[0;36msave_frames\u001b[0;34m(video_list, zip_path, four_by_three)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# loop to the next frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of images saved: {frame_count}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vidcap = cv2.VideoCapture(video_files[0])\n",
        "video_length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT) / 24)\n",
        "success, image = vidcap.read()\n",
        "image"
      ],
      "metadata": {
        "id": "kWFTFKURPqze"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}