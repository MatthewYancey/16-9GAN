{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewYancey/GANime/blob/master/src/train_lama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfxMXJnq_kzW"
      },
      "source": [
        "# LaMa Training Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bouI0_AzCRZy"
      },
      "source": [
        "## Imports and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "885wpFfz2zLh"
      },
      "outputs": [],
      "source": [
        "!pip install kornia\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "sys.path.append('/content/gdrive/MyDrive/repos/GANime/src')\n",
        "from model_helper_functions import gpu_memory, load_checkpoint, apply_mask, apply_comp, checkpoint\n",
        "from model_data_loaders import create_dataloaders\n",
        "from model_lama import Generator, Discriminator, weights_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rw3URZEO3MZm"
      },
      "outputs": [],
      "source": [
        "# network parameters\n",
        "BATCH_SIZE = 15\n",
        "LEARNING_RATE_GEN = 0.001\n",
        "LEARNING_RATE_DISC = 0.0001\n",
        "N_EPOCHS = 100\n",
        "ALPHA_WEIGHT = 0.0004\n",
        "\n",
        "# hardware\n",
        "N_GPU = 1\n",
        "N_WORKERS = 1\n",
        "\n",
        "# image\n",
        "IMG_HEIGHT = 288\n",
        "IMG_WIDTH = 512\n",
        "SINGLE_SIDE = 64\n",
        "\n",
        "TEST_REFERENCES = [2800, 8000, 17850, 3000]\n",
        "\n",
        "# directories\n",
        "ZIP_PATH_TRAIN = '/content/gdrive/My Drive/repos/GANime/data_out/pokemon/train.zip'\n",
        "IMG_DIR_TRAIN = '/content/frames/train/'\n",
        "ZIP_PATH_VAL = '/content/gdrive/My Drive/repos/GANime/data_out/pokemon/validate.zip'\n",
        "IMG_DIR_VAL = '/content/frames/validate/'\n",
        "ZIP_PATH_TEST = '/content/gdrive/My Drive/repos/GANime/data_out/pokemon/test.zip'\n",
        "IMG_DIR_TEST = '/content/frames/test/'\n",
        "LOG_DIR = '/content/gdrive/My Drive/repos/GANime/data_out/logs/ffc/'\n",
        "PREV_CHECKPOINT = '/content/gdrive/My Drive/repos/GANime/data_out/logs/ffc/checkpoint.pt' # set to None to not load and create a new log folder\n",
        "PREV_CHECKPOINT = None # set to None to not load and create a new log folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PT61eB_hRSM4"
      },
      "outputs": [],
      "source": [
        "# unzips images\n",
        "if os.path.exists(IMG_DIR_TRAIN) == False:\n",
        "    shutil.unpack_archive(ZIP_PATH_TRAIN, IMG_DIR_TRAIN, 'zip')\n",
        "    shutil.unpack_archive(ZIP_PATH_VAL, IMG_DIR_VAL, 'zip')\n",
        "    shutil.unpack_archive(ZIP_PATH_TEST, IMG_DIR_TEST, 'zip')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finds the dataset size and the number of batches we'll have to process\n",
        "dataset_size = len(glob.glob(f'{IMG_DIR_TRAIN}*'))\n",
        "n_batches = dataset_size // BATCH_SIZE\n",
        "print(f'Number of images: {dataset_size}')\n",
        "print(f'Number of batches: {n_batches}')"
      ],
      "metadata": {
        "id": "aZNK4FBFYI7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiKyuXpSRBDo"
      },
      "outputs": [],
      "source": [
        "# sets what device to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and N_GPU > 0) else \"cpu\")\n",
        "print(f'Device: {device}')\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4NfzEuXCccW"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DLEwB1B5Y-6"
      },
      "outputs": [],
      "source": [
        "dataloader_train, dataloader_val, dataloader_test = create_dataloaders(BATCH_SIZE, N_WORKERS, IMG_DIR_TRAIN, IMG_DIR_VAL, IMG_DIR_TEST, dataset_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rphdi8N1CiiX"
      },
      "source": [
        "## Networks, Loss Functions, and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtE6YhY53FrI"
      },
      "outputs": [],
      "source": [
        "gen = Generator().to(device)\n",
        "gen.apply(weights_init)\n",
        "disc = Discriminator(IMG_WIDTH, SINGLE_SIDE).to(device)\n",
        "disc.apply(weights_init)\n",
        "gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNpFXQTnZuh_"
      },
      "outputs": [],
      "source": [
        "loss_bce = nn.BCELoss()\n",
        "loss_mse = nn.MSELoss()\n",
        "optimizer_gen = optim.Adadelta(gen.parameters())\n",
        "optimizer_disc = optim.Adadelta(disc.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63H_ZHSZmFfL"
      },
      "outputs": [],
      "source": [
        "# loads the checkpoint\n",
        "gen, optimizer_gen, disc, optimizer_disc, batch_counter = load_checkpoint(PREV_CHECKPOINT, LOG_DIR, gen, optimizer_gen, disc, optimizer_disc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_lWXZ2i6cbd"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgZ-sLbSvWPv"
      },
      "outputs": [],
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "    # gets data for the generator\n",
        "    for i, batch in enumerate(dataloader_train, 0):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        # apply mask to the images\n",
        "        batch_mask = batch.clone()\n",
        "        batch_mask = apply_mask(batch_mask, IMG_WIDTH, SINGLE_SIDE)\n",
        "\n",
        "        # only trains the discriminator every 9 batches\n",
        "        if i % 9 == 0:\n",
        "            #############################\n",
        "            # Discriminator\n",
        "            #############################\n",
        "            disc.zero_grad()\n",
        "            disc_output = disc(batch)\n",
        "            disc_loss_real = loss_bce(disc_output, torch.ones(disc_output.shape[0]).cuda())\n",
        "            disc_accuracy = (disc_output.round() == torch.ones(disc_output.shape[0]).cuda()).sum()\n",
        "            disc_loss_real.backward()\n",
        "\n",
        "            # passes fake images to feed the discriminator\n",
        "            gen_output = gen(batch_mask)\n",
        "            gen_output = apply_comp(batch, gen_output, IMG_WIDTH, SINGLE_SIDE)\n",
        "            disc_output = disc(gen_output) # try taking detach off\n",
        "            disc_accuracy += (disc_output.round() == torch.zeros(disc_output.shape[0]).cuda()).sum()\n",
        "            disc_accuracy = disc_accuracy / (BATCH_SIZE * 2)\n",
        "            disc_loss_fake = loss_bce(disc_output, torch.zeros(disc_output.shape[0]).to(device))\n",
        "            disc_loss_fake.backward()\n",
        "\n",
        "            # optimized the discriminator\n",
        "            disc_loss = (disc_loss_real + disc_loss_fake) / 200  # scale the loss between 0 and 1\n",
        "            optimizer_disc.step()\n",
        "\n",
        "        #############################\n",
        "        # Generater\n",
        "        #############################\n",
        "        gen.zero_grad()\n",
        "        gen_output = gen(batch_mask)\n",
        "\n",
        "        # combines the sides from the generator with the 4:3 image and calculates the mse loss against the orginal full image\n",
        "        gen_output = apply_comp(batch, gen_output, IMG_WIDTH, SINGLE_SIDE)\n",
        "\n",
        "        disc_output = disc(gen_output)\n",
        "        \n",
        "        # calculates the loss\n",
        "        gen_train_loss_mse = loss_mse(gen_output, batch)\n",
        "        gen_train_loss_bce = loss_bce(disc_output, torch.ones(disc_output.shape[0]).cuda())\n",
        "        gen_train_loss = (gen_train_loss_mse + gen_train_loss_bce*ALPHA_WEIGHT) / 2\n",
        "\n",
        "        # error and optimize\n",
        "        gen_train_loss.backward()\n",
        "        optimizer_gen.step()\n",
        "\n",
        "        # prints the status and checkpoints every so often\n",
        "        if i % 100 == 0:\n",
        "            print(f'Epoch: {epoch}/{N_EPOCHS}, Batch: {i}/{n_batches}, Total Images {batch_counter * BATCH_SIZE}, Gen Train Loss: {gen_train_loss:.4f}, Disc Accuracy: {disc_accuracy:.4f}, CUDA Memory: {(torch.cuda.memory_allocated() / 10**9):.4f}')\n",
        "\n",
        "            if i % 1000 == 0:\n",
        "                # gets the testing MSE\n",
        "                batch = next(iter(dataloader_val))\n",
        "                batch = batch.to(device)\n",
        "                batch_mask = batch.clone()\n",
        "                batch_mask = apply_mask(batch_mask, IMG_WIDTH, SINGLE_SIDE)\n",
        "                with torch.no_grad():\n",
        "                    gen_output = gen(batch_mask)\n",
        "                gen_output = apply_comp(batch, gen_output, IMG_WIDTH, SINGLE_SIDE)\n",
        "\n",
        "                # calculates the loss\n",
        "                disc_output = disc(gen_output)\n",
        "                val_loss_bce = loss_bce(disc_output, torch.ones(disc_output.shape[0]).cuda())\n",
        "                val_loss_mse = loss_mse(gen_output, batch)\n",
        "                val_loss = (val_loss_mse + val_loss_bce*ALPHA_WEIGHT) / 2\n",
        "\n",
        "                checkpoint(i,\n",
        "                           batch_counter,\n",
        "                           disc_loss.item(),\n",
        "                           disc_accuracy,\n",
        "                           gen_train_loss.item(),\n",
        "                           gen_train_loss_mse.item(),\n",
        "                           val_loss.item(),\n",
        "                           val_loss_mse.item(),\n",
        "                           LOG_DIR,\n",
        "                           gen,\n",
        "                           optimizer_gen,\n",
        "                           disc,\n",
        "                           optimizer_disc,\n",
        "                           dataloader_test,\n",
        "                           TEST_REFERENCES,\n",
        "                           IMG_HEIGHT,\n",
        "                           IMG_WIDTH,\n",
        "                           SINGLE_SIDE)\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        batch_counter += 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "train_lama.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}