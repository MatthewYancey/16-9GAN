{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model_global_and_local_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewYancey/GANime/blob/master/src/model_global_and_local_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfxMXJnq_kzW"
      },
      "source": [
        "# GANime Globally and Locally Consistent Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bouI0_AzCRZy"
      },
      "source": [
        "## Imports and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "885wpFfz2zLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bfd7ae6-82ef-444f-87d6-cc9846b7509b"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "sys.path.append('/content/gdrive/MyDrive/repos/GANime/src')\n",
        "from helper_functions import apply_mask, apply_padding, apply_comp, apply_scale, load_checkpoint, checkpoint, gpu_memory\n",
        "from data_loaders import create_dataloaders\n",
        "from networks_global_and_local import Generator, Discriminator, weights_init"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw3URZEO3MZm"
      },
      "source": [
        "# network parameters\n",
        "BATCH_SIZE = 15\n",
        "DATASET_SIZE = 100000\n",
        "N_BATCHES = DATASET_SIZE // BATCH_SIZE\n",
        "N_GPU = 1\n",
        "N_WORKERS = 1\n",
        "N_EPOCHS = 100\n",
        "LEARNING_RATE = 0.0002\n",
        "ALPHA_WEIGHT = 0.99\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "# image\n",
        "IMG_HEIGHT = 288\n",
        "IMG_WIDTH = 512\n",
        "SINGLE_SIDE = 64\n",
        "\n",
        "# tensorboard\n",
        "TRAIN_REFERENCE_INDEX = 200\n",
        "VAL_REFERENCE_INDEX = 100\n",
        "TEST_REFERENCE_INDEX = 20\n",
        "\n",
        "# cost weights\n",
        "WEIGHT_DECAY = 0.05\n",
        "\n",
        "# directories\n",
        "ZIP_PATH_TRAIN = '/content/gdrive/My Drive/repos/GANime/data_out/pokemon/train.zip'\n",
        "IMG_DIR_TRAIN = '/content/frames/train/'\n",
        "ZIP_PATH_VAL = '/content/gdrive/My Drive/repos/GANime/data_out/pokemon/validate.zip'\n",
        "IMG_DIR_VAL = '/content/frames/validate/'\n",
        "ZIP_PATH_TEST = '/content/gdrive/My Drive/repos/GANime/data_out/pokemon/test.zip'\n",
        "IMG_DIR_TEST = '/content/frames/test/'\n",
        "# LOG_DIR = '/content/gdrive/My Drive/repos/GANime/data_out/logs/global_and_local/'\n",
        "LOG_DIR = '/content/temp/global_and_local/'\n",
        "\n",
        "# PREV_CHECKPOINT = '/content/gdrive/My Drive/repos/GANime/data_out/logs/global_and_local/checkpoint.pt' # set to none to not load and create a new log folder\n",
        "PREV_CHECKPOINT = None # set to none to not load and create a new log folder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT61eB_hRSM4"
      },
      "source": [
        "# unzips images\n",
        "if os.path.exists(IMG_DIR_TRAIN) == False:\n",
        "    shutil.unpack_archive(ZIP_PATH_TRAIN, IMG_DIR_TRAIN, 'zip')\n",
        "    shutil.unpack_archive(ZIP_PATH_VAL, IMG_DIR_VAL, 'zip')\n",
        "    shutil.unpack_archive(ZIP_PATH_TEST, IMG_DIR_TEST, 'zip')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiKyuXpSRBDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1150790-2ace-4278-bdec-6de6298a724d"
      },
      "source": [
        "# sets what device to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and N_GPU > 0) else \"cpu\")\n",
        "print(f'Device: {device}')\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-67eee1a6-f8fb-16fe-195b-c6ef33332e5d)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4NfzEuXCccW"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DLEwB1B5Y-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8e2368-c572-4bdf-8c5e-75a49ba94c1b"
      },
      "source": [
        "dataloader_train, dataloader_val, dataloader_test = create_dataloaders(BATCH_SIZE, N_WORKERS, IMG_DIR_TRAIN, IMG_DIR_VAL, IMG_DIR_TEST, DATASET_SIZE)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset\n",
            "Number of images: 21623\n",
            "Size of dataset: 21623\n",
            "Validation Dataset\n",
            "Number of images: 6178\n",
            "Size of dataset: 6178\n",
            "Testing Dataset\n",
            "Number of images: 3089\n",
            "Size of dataset: 3089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rphdi8N1CiiX"
      },
      "source": [
        "## Networks, Loss Functions, and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtE6YhY53FrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adbb4a35-d19a-4490-9837-5b5ea45a56c3"
      },
      "source": [
        "gen = Generator(IMG_WIDTH, SINGLE_SIDE).to(device)\n",
        "gen.apply(weights_init)\n",
        "disc = Discriminator(IMG_WIDTH, SINGLE_SIDE, DROPOUT_RATE).to(device)\n",
        "disc.apply(weights_init)\n",
        "gpu_memory()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allocated memory: 0.420852224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNpFXQTnZuh_"
      },
      "source": [
        "loss_bce = nn.BCELoss()\n",
        "loss_mse = nn.MSELoss()\n",
        "# optimizer_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.9))\n",
        "optimizer_gen = optim.Adadelta(gen.parameters())\n",
        "optimizer_disc = optim.Adadelta(disc.parameters())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63H_ZHSZmFfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f61ef6b-b873-402c-c918-55f8c81cff01"
      },
      "source": [
        "# loads the checkpoint\n",
        "gen, optimizer_gen, disc, optimizer_disc, batch_counter = load_checkpoint(PREV_CHECKPOINT, LOG_DIR, gen, optimizer_gen, disc, optimizer_disc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No log folder found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_lWXZ2i6cbd"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgZ-sLbSvWPv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "35cd0e2d-80c6-45a5-c0b2-0181883db52f"
      },
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "    # gets data for the generator\n",
        "    for i, batch in enumerate(dataloader_train, 0):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        #############################\n",
        "        # Discriminator\n",
        "        #############################\n",
        "        disc.zero_grad()\n",
        "        disc_output = disc(batch)\n",
        "        disc_loss_real = loss_bce(disc_output, torch.ones(disc_output.shape[0]).cuda())\n",
        "        disc_accuracy = (disc_output.round() == torch.ones(disc_output.shape[0]).cuda()).sum()\n",
        "        disc_loss_real.backward()\n",
        "\n",
        "        # apply mask to the images\n",
        "        batch_mask = batch.clone()\n",
        "        batch_mask = apply_mask(batch_mask, IMG_WIDTH, SINGLE_SIDE)\n",
        "\n",
        "        # passes fake images to feed the discriminator\n",
        "        gen_output = gen(batch_mask)\n",
        "        gen_output = apply_comp(batch, gen_output, IMG_WIDTH, SINGLE_SIDE)\n",
        "        disc_output = disc(gen_output) # try taking detach off\n",
        "        disc_accuracy += (disc_output.round() == torch.zeros(disc_output.shape[0]).cuda()).sum()\n",
        "        disc_accuracy = disc_accuracy / (BATCH_SIZE * 2)\n",
        "        disc_loss_fake = loss_bce(disc_output, torch.zeros(disc_output.shape[0]).to(device))\n",
        "        disc_loss_fake.backward()\n",
        "\n",
        "        # optimized the discriminator\n",
        "        disc_loss = (disc_loss_real + disc_loss_fake) / 200  # scale the loss between 0 and 1\n",
        "        optimizer_disc.step()\n",
        "\n",
        "        #############################\n",
        "        # Generater\n",
        "        #############################\n",
        "        gen.zero_grad()\n",
        "        gen_output = gen(batch_mask)\n",
        "\n",
        "        # combines the sides from the generator with the 4:3 image and calculates the mse loss against the orginal full image\n",
        "        gen_output = apply_comp(batch, gen_output, IMG_WIDTH, SINGLE_SIDE)\n",
        "        disc_output = disc(gen_output)\n",
        "        \n",
        "        # calculates the loss\n",
        "        gen_train_loss_mse = loss_mse(gen_output, batch)\n",
        "        gen_train_loss_bce = loss_bce(disc_output, torch.ones(disc_output.shape[0]).cuda())\n",
        "        gen_train_loss = (gen_train_loss_mse + gen_train_loss_bce * 0.01) / 2\n",
        "\n",
        "        # error and optimize\n",
        "        gen_train_loss.backward()\n",
        "        optimizer_gen.step()\n",
        "\n",
        "        # prints the status and checkpoints every so often\n",
        "        if i % 10 == 0:\n",
        "            # gets the testing MSE\n",
        "            batch = next(iter(dataloader_val))\n",
        "            batch = batch.to(device)\n",
        "            batch_mask = batch.clone()\n",
        "            batch_mask = apply_mask(batch_mask, IMG_WIDTH, SINGLE_SIDE)\n",
        "            with torch.no_grad():\n",
        "                gen_output = gen(batch_mask)\n",
        "            gen_output = apply_comp(batch, gen_output, IMG_WIDTH, SINGLE_SIDE)\n",
        "\n",
        "            # calculates the loss\n",
        "            disc_output = disc(gen_output)\n",
        "            val_loss_bce = loss_bce(disc_output, torch.ones(disc_output.shape[0]).cuda())\n",
        "            val_loss_mse = loss_mse(gen_output, batch)\n",
        "            val_loss = val_loss_mse*ALPHA_WEIGHT + val_loss_bce*(1-ALPHA_WEIGHT)\n",
        "\n",
        "            print(f'Epoch: {epoch}/{N_EPOCHS}, Batch: {i}/{N_BATCHES}, Total Images {batch_counter * BATCH_SIZE}, Gen Train Loss: {gen_train_loss:.4f}, Gen Val Loss: {val_loss:.4f}, Disc Accuracy: {disc_accuracy:.4f}, CUDA Memory: {(torch.cuda.memory_allocated() / 10**9):.4f}')\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                checkpoint(batch_counter,\n",
        "                           disc_loss.item(),\n",
        "                           disc_accuracy,\n",
        "                           gen_train_loss.item(),\n",
        "                           gen_train_loss_mse.item(),\n",
        "                           val_loss.item(),\n",
        "                           val_loss_mse.item(),\n",
        "                           LOG_DIR,\n",
        "                           gen,\n",
        "                           optimizer_gen,\n",
        "                           disc,\n",
        "                           optimizer_disc,\n",
        "                           dataloader_train,\n",
        "                           TRAIN_REFERENCE_INDEX,\n",
        "                           dataloader_val,\n",
        "                           VAL_REFERENCE_INDEX,\n",
        "                           IMG_HEIGHT,\n",
        "                           IMG_WIDTH,\n",
        "                           SINGLE_SIDE)\n",
        "\n",
        "        batch_counter += 1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/100, Batch: 0/6666, Total Images 0, Gen Train Loss: 0.0629, Gen Val Loss: 0.0908, Disc Accuracy: 0.5000, CUDA Memory: 2.534216192\n",
            "Saving reference images\n",
            "Saved checkpoint\n",
            "Epoch: 0/100, Batch: 100/6666, Total Images 1500, Gen Train Loss: 0.0300, Gen Val Loss: 0.0505, Disc Accuracy: 0.5000, CUDA Memory: 3.332958208\n",
            "Epoch: 0/100, Batch: 200/6666, Total Images 3000, Gen Train Loss: 0.0224, Gen Val Loss: 0.0462, Disc Accuracy: 0.5000, CUDA Memory: 3.329951744\n",
            "Epoch: 0/100, Batch: 300/6666, Total Images 4500, Gen Train Loss: 0.0193, Gen Val Loss: 0.0318, Disc Accuracy: 0.5667, CUDA Memory: 3.329820672\n",
            "Epoch: 0/100, Batch: 400/6666, Total Images 6000, Gen Train Loss: 0.0186, Gen Val Loss: 0.0392, Disc Accuracy: 0.7000, CUDA Memory: 3.328886784\n",
            "Epoch: 0/100, Batch: 500/6666, Total Images 7500, Gen Train Loss: 0.0198, Gen Val Loss: 0.0285, Disc Accuracy: 0.6000, CUDA Memory: 3.327821824\n",
            "Epoch: 0/100, Batch: 600/6666, Total Images 9000, Gen Train Loss: 0.0172, Gen Val Loss: 0.0302, Disc Accuracy: 0.5000, CUDA Memory: 3.3290752\n",
            "Epoch: 0/100, Batch: 700/6666, Total Images 10500, Gen Train Loss: 0.0146, Gen Val Loss: 0.0241, Disc Accuracy: 0.5000, CUDA Memory: 3.329058816\n",
            "Epoch: 0/100, Batch: 800/6666, Total Images 12000, Gen Train Loss: 0.0267, Gen Val Loss: 0.0441, Disc Accuracy: 0.6000, CUDA Memory: 3.330107904\n",
            "Epoch: 0/100, Batch: 900/6666, Total Images 13500, Gen Train Loss: 0.0254, Gen Val Loss: 0.0464, Disc Accuracy: 0.5000, CUDA Memory: 3.32801024\n",
            "Epoch: 0/100, Batch: 1000/6666, Total Images 15000, Gen Train Loss: 0.0199, Gen Val Loss: 0.0341, Disc Accuracy: 0.6667, CUDA Memory: 3.327371264\n",
            "Saved checkpoint\n",
            "Epoch: 0/100, Batch: 1100/6666, Total Images 16500, Gen Train Loss: 0.0354, Gen Val Loss: 0.0504, Disc Accuracy: 0.7333, CUDA Memory: 3.328550912\n",
            "Epoch: 0/100, Batch: 1200/6666, Total Images 18000, Gen Train Loss: 0.0258, Gen Val Loss: 0.0465, Disc Accuracy: 0.8667, CUDA Memory: 3.327666176\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a5b6025cb929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# calculates the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mgen_train_loss_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mgen_train_loss_bce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_bce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisc_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mgen_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgen_train_loss_mse\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgen_train_loss_bce\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9vOr7YbNEyiO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}