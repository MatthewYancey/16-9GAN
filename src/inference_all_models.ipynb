{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewYancey/GANime/blob/master/src/inference_all_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfxMXJnq_kzW"
      },
      "source": [
        "# Globally and Locally Consistant Images Inference\n",
        "This notebook is for reviewing batches of images through the global and local model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bouI0_AzCRZy"
      },
      "source": [
        "## Imports and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "885wpFfz2zLh",
        "outputId": "ae6b10f2-6e05-4d3b-a094-757c1e33b001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "sys.path.append('/content/gdrive/MyDrive/repos/GANime/src')\n",
        "from model_helper_functions import apply_mask, apply_padding, apply_comp, apply_scale, load_checkpoint_inference, checkpoint\n",
        "from model_data_loaders import create_dataloaders\n",
        "from model_gal import Generator as _gen_gal\n",
        "from model_context_encoders import Generator as _gen_ce\n",
        "from model_lama import Generator as _gen_lama\n",
        "# from model_gal import gal_Generator, Discriminator, weights_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rw3URZEO3MZm"
      },
      "outputs": [],
      "source": [
        "# network parameters\n",
        "BATCH_SIZE = 15\n",
        "N_EPOCHS = 100\n",
        "ALPHA_WEIGHT = 0.0004\n",
        "\n",
        "# hardware\n",
        "N_GPU = 1\n",
        "N_WORKERS = 1\n",
        "\n",
        "# image\n",
        "IMG_HEIGHT = 288\n",
        "IMG_WIDTH = 512\n",
        "SINGLE_SIDE = 64\n",
        "\n",
        "TEST_REFERENCES = [2800, 8000, 17850, 3000]\n",
        "\n",
        "# directories\n",
        "ZIP_PATH_TRAIN = '/content/gdrive/My Drive/repos/GANime/data_out/pokemon/train.zip'\n",
        "IMG_DIR_TRAIN = '/content/frames/train/'\n",
        "ZIP_PATH_VAL = '/content/gdrive/My Drive/repos/GANime/data_out/pokemon/validate.zip'\n",
        "IMG_DIR_VAL = '/content/frames/validate/'\n",
        "ZIP_PATH_TEST = '/content/gdrive/My Drive/repos/GANime/data_out/pokemon/test.zip'\n",
        "IMG_DIR_TEST = '/content/frames/test/'\n",
        "\n",
        "CHECKPOINT_CE = '/content/gdrive/My Drive/repos/GANime/data_out/logs/model_context_encoders/checkpoint.pt'\n",
        "CHECKPOINT_GAL = '/content/gdrive/My Drive/repos/GANime/data_out/logs/global_and_local/checkpoint.pt'\n",
        "CHECKPOINT_LAMA = '/content/gdrive/My Drive/repos/GANime/data_out/logs/ffc/checkpoint.pt'\n",
        "\n",
        "TEMP_DIR = '/content/saved_frames/'\n",
        "OUTPUT_DIR = '/content/gdrive/MyDrive/repos/GANime/data_out/test_output/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PT61eB_hRSM4"
      },
      "outputs": [],
      "source": [
        "# unzips images\n",
        "if os.path.exists(IMG_DIR_TRAIN) == False:\n",
        "    shutil.unpack_archive(ZIP_PATH_TRAIN, IMG_DIR_TRAIN, 'zip')\n",
        "    shutil.unpack_archive(ZIP_PATH_VAL, IMG_DIR_VAL, 'zip')\n",
        "    shutil.unpack_archive(ZIP_PATH_TEST, IMG_DIR_TEST, 'zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiKyuXpSRBDo",
        "outputId": "283f8c9d-344b-43db-d76e-d05edecf6748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# sets what device to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and N_GPU > 0) else \"cpu\")\n",
        "print(f'Device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8dmZW00ToKD",
        "outputId": "a940e36b-f581-49fe-c6d3-23acef99a05f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset\n",
            "Number of images: 429979\n",
            "Size of dataset: 429979\n",
            "Validation Dataset\n",
            "Number of images: 122851\n",
            "Size of dataset: 122851\n",
            "Testing Dataset\n",
            "Number of images: 61426\n",
            "no transform\n",
            "Size of dataset: 61426\n"
          ]
        }
      ],
      "source": [
        "dataloader_train, dataloader_val, dataloader_test = create_dataloaders(BATCH_SIZE,\n",
        "                                                                       N_WORKERS,\n",
        "                                                                       IMG_DIR_TRAIN,\n",
        "                                                                       IMG_DIR_VAL,\n",
        "                                                                       IMG_DIR_TEST,\n",
        "                                                                       shuffle_images=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_gal = _gen_gal(IMG_WIDTH, SINGLE_SIDE).to(device)\n",
        "gen_gal = load_checkpoint_inference(CHECKPOINT_GAL, gen_gal)\n",
        "\n",
        "gen_ce = _gen_ce(IMG_WIDTH, SINGLE_SIDE).to(device)\n",
        "gen_ce = load_checkpoint_inference(CHECKPOINT_CE, gen_ce)\n",
        "\n",
        "gen_lama = _gen_lama().to(device)\n",
        "gen_lama = load_checkpoint_inference(CHECKPOINT_LAMA, gen_lama)"
      ],
      "metadata": {
        "id": "YzfV1FGJMOta",
        "outputId": "0697129d-c9b5-4105-c7eb-14cad0bfbb69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded checkpoint from /content/gdrive/My Drive/repos/GANime/data_out/logs/global_and_local/checkpoint.pt\n",
            "Loaded checkpoint from /content/gdrive/My Drive/repos/GANime/data_out/logs/model_context_encoders/checkpoint.pt\n",
            "Loaded checkpoint from /content/gdrive/My Drive/repos/GANime/data_out/logs/ffc/checkpoint.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_images(gen, model_name):\n",
        "    print(f'Processing {model_name}')\n",
        "\n",
        "    if os.path.exists(TEMP_DIR):\n",
        "        shutil.rmtree(TEMP_DIR)\n",
        "    os.mkdir(TEMP_DIR)\n",
        "\n",
        "    img_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch in enumerate(dataloader_test, 0):\n",
        "                batch = batch.to(device)\n",
        "\n",
        "                gen_output = gen(apply_mask(batch.to(device), IMG_WIDTH, SINGLE_SIDE))\n",
        "                batch = apply_comp(batch.to(device), gen_output, IMG_WIDTH, SINGLE_SIDE)\n",
        "                batch = apply_scale(batch)\n",
        "                batch = batch.detach()\n",
        "                batch = batch[:64].cpu()\n",
        "                batch  = batch.numpy() # make sure tensor is on cpu\n",
        "\n",
        "                for img_i in range(batch.shape[0]):\n",
        "                    img = batch[img_i, :, :, :]\n",
        "                    img = np.transpose(img, (1, 2, 0))\n",
        "                    img = (img * 255).astype(np.uint8)\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "                    img_name = f'{TEMP_DIR}{model_name}_{img_count}.jpg'\n",
        "                    cv2.imwrite(img_name, img)\n",
        "                    img_count += 1\n",
        "\n",
        "    shutil.make_archive(f'{OUTPUT_DIR}{model_name}', 'zip', TEMP_DIR)\n",
        "\n",
        "\n",
        "gens = [[gen_gal, 'gal'], [gen_ce, 'ce'], [gen_lama, 'lama']]\n",
        "for g in gens:\n",
        "    save_images(g[0], g[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnmW8zxXS1EF",
        "outputId": "1914e226-c8b4-4e8d-ca98-85837eb4cc2a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing gal\n",
            "Processing ce\n",
            "Processing lama\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model_preview.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}