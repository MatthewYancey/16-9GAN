{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_lama_default.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOPbW7bSHZAFh7gTN6i1bI4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewYancey/GANime/blob/master/src/train_lama_default.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tain LaMa\n",
        "This notebok runs the default training for LaMa"
      ],
      "metadata": {
        "id": "iVrGyIPupkW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -e detectron2_repo"
      ],
      "metadata": {
        "id": "vTaQAZl0wSFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "3P4-_KddMXYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_zip = '/content/gdrive/MyDrive/repos/GANime/data_out/pokemon/train_png.zip'\n",
        "val_zip = '/content/gdrive/MyDrive/repos/GANime/data_out/pokemon/test_masks.zip'\n",
        "eval_zip = '/content/gdrive/MyDrive/repos/GANime/data_out/pokemon/test_masks.zip'\n",
        "dataset_dir = '/content/lama/my_dataset/'"
      ],
      "metadata": {
        "id": "4YQmQ5TLe-2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n> Cloning the repo')\n",
        "!git clone https://github.com/saic-mdal/lama.git\n",
        "\n",
        "print('\\n> Install dependencies')\n",
        "!pip install -r lama/requirements.txt --quiet\n",
        "!pip install wget --quiet\n",
        "\n",
        "print('\\n> Changing the dir to:')\n",
        "% cd /content/lama\n",
        "\n",
        "# downloads the models for evaluations\n",
        "print('Downloading resnet model for evaluation')\n",
        "!mkdir -p ade20k/ade20k-resnet50dilated-ppm_deepsup/\n",
        "!wget -P ade20k/ade20k-resnet50dilated-ppm_deepsup/ http://sceneparsing.csail.mit.edu/model/pytorch/ade20k-resnet50dilated-ppm_deepsup/encoder_epoch_20.pth\n",
        "\n",
        "# see if you don't need this\n",
        "# print('\\n> Download the model')\n",
        "# !curl -L $(yadisk-direct https://disk.yandex.ru/d/EgqaSnLohjuzAg) -o lama-models.zip\n",
        "# !unzip lama-models.zip\n",
        "\n",
        "print('>fixing opencv')\n",
        "!pip uninstall opencv-python-headless -y --quiet\n",
        "!pip install opencv-python-headless==4.1.2.30 --quiet\n",
        "\n",
        "print('\\n> Init mask-drawing code')\n",
        "import base64, os\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wget\n",
        "from shutil import copyfile\n",
        "import shutil"
      ],
      "metadata": {
        "id": "ACQUc8OQT4uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val_source # 2000 or more images\n",
        "# visual_test_source # 100 or more images\n",
        "# eval_source # 2000 or more images\n",
        "\n",
        "# copy the training set over\n",
        "try:\n",
        "    os.mkdir(dataset_dir)\n",
        "except FileExistsError:\n",
        "    pass\n",
        "shutil.copy(val_zip, dataset_dir + 'val.zip')\n",
        "shutil.unpack_archive(dataset_dir + 'val.zip', dataset_dir + '/val/')\n",
        "\n",
        "# makes a copy for eval and visual test\n",
        "shutil.copytree(dataset_dir + 'val/', dataset_dir + 'eval/')\n",
        "shutil.copytree(dataset_dir + 'val/', dataset_dir + 'visual_test/')"
      ],
      "metadata": {
        "id": "AgZ2BaVXkede"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copies images to the training folder\n",
        "img_list = glob.glob(dataset_dir + '/val/*')\n",
        "print(f'Number of images: {len(img_list)}')\n",
        "img_list = [f for f in img_list if 'mask' not in f]\n",
        "print(f'Number of images: {len(img_list)}')"
      ],
      "metadata": {
        "id": "8A-44i9x9UVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glob.glob(dataset_dir + '/train/*')[0]"
      ],
      "metadata": {
        "id": "kLlG1ZMDo8n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# picks 130k images and resizes them\n",
        "if os.path.isdir(dataset_dir + 'train/'):\n",
        "    shutil.rmtree(dataset_dir + 'train/')\n",
        "os.mkdir(dataset_dir + 'train/')\n",
        "\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "for i in range(130000):\n",
        "    img_file = random.choice(img_list)\n",
        "    img = cv2.imread(img_file)\n",
        "    cv2.imwrite(dataset_dir + 'train/' + os.path.basename(img_file).replace('.png', '.jpg'), img)\n",
        "    \n",
        "    if i % 10000 == 0:\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "npMM6xB09Vst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# makes the config file for training\n",
        "!touch my_dataset.yaml\n",
        "!echo \"data_root_dir: $(pwd)/my_dataset/\" >> my_dataset.yaml\n",
        "!echo \"out_root_dir: $(pwd)/experiments/\" >> my_dataset.yaml\n",
        "!echo \"tb_dir: $(pwd)/tb_logs/\" >> my_dataset.yaml\n",
        "!mv my_dataset.yaml ${PWD}/configs/training/location/\n",
        "\n",
        "# change /content/lama/configs/training/trainer/any_gpu_large_ssim_ddp_final.yaml limit_train_batches: 2600 # was 25000"
      ],
      "metadata": {
        "id": "FJbZWmtanNZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export TORCH_HOME=$(pwd) && export USER='matt' && export PYTHONPATH=. && python3 bin/train.py -cn lama-fourier location=my_dataset data.batch_size=10\n",
        "# !cat ${PWD}/configs/training/data/abl-04-256-mh-dist"
      ],
      "metadata": {
        "id": "ZUQVVnILn7H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vP1BnMXmucG7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}