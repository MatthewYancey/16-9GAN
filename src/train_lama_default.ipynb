{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_lama_default.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2qTdj5039tP2Hl+7bD0tl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewYancey/GANime/blob/master/src/train_lama_default.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tain LaMa\n",
        "This notebok runs the default training for LaMa"
      ],
      "metadata": {
        "id": "iVrGyIPupkW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -e detectron2_repo"
      ],
      "metadata": {
        "id": "vTaQAZl0wSFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P4-_KddMXYc",
        "outputId": "584c782e-ad21-4e4f-da84-1a1f14eef61b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_zip = '/content/gdrive/MyDrive/repos/GANime/data_out/pokemon/train_png.zip'\n",
        "val_zip = '/content/gdrive/MyDrive/repos/GANime/data_out/pokemon/test_masks.zip'\n",
        "eval_zip = '/content/gdrive/MyDrive/repos/GANime/data_out/pokemon/test_masks.zip'\n",
        "dataset_dir = '/content/lama/my_dataset/'"
      ],
      "metadata": {
        "id": "4YQmQ5TLe-2n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n> Cloning the repo')\n",
        "!git clone https://github.com/saic-mdal/lama.git\n",
        "\n",
        "print('\\n> Install dependencies')\n",
        "!pip install -r lama/requirements.txt --quiet\n",
        "!pip install wget --quiet\n",
        "\n",
        "print('\\n> Changing the dir to:')\n",
        "% cd /content/lama\n",
        "\n",
        "# downloads the models for evaluations\n",
        "print('Downloading resnet model for evaluation')\n",
        "!mkdir -p ade20k/ade20k-resnet50dilated-ppm_deepsup/\n",
        "!wget -P ade20k/ade20k-resnet50dilated-ppm_deepsup/ http://sceneparsing.csail.mit.edu/model/pytorch/ade20k-resnet50dilated-ppm_deepsup/encoder_epoch_20.pth\n",
        "\n",
        "# see if you don't need this\n",
        "# print('\\n> Download the model')\n",
        "# !curl -L $(yadisk-direct https://disk.yandex.ru/d/EgqaSnLohjuzAg) -o lama-models.zip\n",
        "# !unzip lama-models.zip\n",
        "\n",
        "print('>fixing opencv')\n",
        "!pip uninstall opencv-python-headless -y --quiet\n",
        "!pip install opencv-python-headless==4.1.2.30 --quiet\n",
        "\n",
        "print('\\n> Init mask-drawing code')\n",
        "import base64, os\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wget\n",
        "from shutil import copyfile\n",
        "import shutil"
      ],
      "metadata": {
        "id": "ACQUc8OQT4uH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638f0b22-cb8c-4777-da88-627c9f441c70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> Cloning the repo\n",
            "Cloning into 'lama'...\n",
            "remote: Enumerating objects: 283, done.\u001b[K\n",
            "remote: Counting objects: 100% (283/283), done.\u001b[K\n",
            "remote: Compressing objects: 100% (205/205), done.\u001b[K\n",
            "remote: Total 283 (delta 73), reused 264 (delta 66), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (283/283), 6.49 MiB | 37.57 MiB/s, done.\n",
            "Resolving deltas: 100% (73/73), done.\n",
            "\n",
            "> Install dependencies\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 70.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 854 kB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 92.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 841 kB 64.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 91.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47 kB 6.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.7 MB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 948 kB 70.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 176 kB 81.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 93.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 93.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 73.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 74.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 86.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.4 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "> Changing the dir to:\n",
            "/content/lama\n",
            "Downloading resnet model for evaluation\n",
            "--2022-02-11 21:27:41--  http://sceneparsing.csail.mit.edu/model/pytorch/ade20k-resnet50dilated-ppm_deepsup/encoder_epoch_20.pth\n",
            "Resolving sceneparsing.csail.mit.edu (sceneparsing.csail.mit.edu)... 128.30.195.26\n",
            "Connecting to sceneparsing.csail.mit.edu (sceneparsing.csail.mit.edu)|128.30.195.26|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95015426 (91M)\n",
            "Saving to: ‘ade20k/ade20k-resnet50dilated-ppm_deepsup/encoder_epoch_20.pth’\n",
            "\n",
            "encoder_epoch_20.pt 100%[===================>]  90.61M  87.8MB/s    in 1.0s    \n",
            "\n",
            "2022-02-11 21:27:42 (87.8 MB/s) - ‘ade20k/ade20k-resnet50dilated-ppm_deepsup/encoder_epoch_20.pth’ saved [95015426/95015426]\n",
            "\n",
            ">fixing opencv\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 266 kB/s \n",
            "\u001b[?25h\n",
            "> Init mask-drawing code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uses the celeb dataset\n",
        "shutil.copy('/content/gdrive/MyDrive/repos/GANime/data_out/data256x256.zip', '/content/lama/data256x256.zip')\n",
        "!bash fetch_data/celebahq_dataset_prepare.sh\n",
        "\n",
        "# generate masks for test and visual_test at the end of epoch\n",
        "!export PYTHONPATH=. && bash fetch_data/celebahq_gen_masks.sh\n",
        "\n",
        "# Run training\n",
        "!export TORCH_HOME=$(pwd) && export USER='matt' && export PYTHONPATH=. && python3 bin/train.py -cn lama-fourier-celeba data.batch_size=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX1y33eCJkpK",
        "outputId": "963f7224-eb9f-404c-955f-ed26171b8eae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rEpoch 0:   5% 360/6592 [02:00<34:51,  2.98it/s, loss=12.5, v_num=0]\rEpoch 0:   5% 360/6592 [02:00<34:51,  2.98it/s, loss=13.6, v_num=0]/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Saving latest checkpoint...\n",
            "Epoch 0, global step 370: val_ssim_fid100_f1_total_mean reached 0.00000 (best 0.00000), saving model to \"/content/lama/experiments/matt_2022-02-11_21-40-54_train_lama-fourier-celeba_/models/epoch=0-step=370.ckpt\" as top 5\n",
            "Epoch 0:   5% 360/6592 [02:10<37:34,  2.76it/s, loss=13.6, v_num=0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# val_source # 2000 or more images\n",
        "# visual_test_source # 100 or more images\n",
        "# eval_source # 2000 or more images\n",
        "\n",
        "# copy the training set over\n",
        "os.mkdir(dataset_dir)\n",
        "shutil.copy(val_zip, dataset_dir + 'val.zip')\n",
        "shutil.unpack_archive(dataset_dir + 'val.zip', dataset_dir + '/val_source/')\n",
        "\n",
        "# makes a copy for eval and visual test\n",
        "shutil.copytree(dataset_dir + 'val_source/', dataset_dir + 'eval_source/')\n",
        "shutil.copytree(dataset_dir + 'val_source/', dataset_dir + 'visual_test_source/')"
      ],
      "metadata": {
        "id": "AgZ2BaVXkede"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copies images to the training folder\n",
        "img_list = glob.glob(dataset_dir + '/val_source/*')\n",
        "print(f'Number of images: {len(img_list)}')\n",
        "img_list = [f for f in img_list if 'mask' not in f]\n",
        "print(f'Number of images: {len(img_list)}')"
      ],
      "metadata": {
        "id": "8A-44i9x9UVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# picks 130k images and resizes them\n",
        "if os.path.isdir(dataset_dir + 'train/'):\n",
        "    shutil.rmtree(dataset_dir + 'train/')\n",
        "os.mkdir(dataset_dir + 'train/')\n",
        "\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "for i in range(130000):\n",
        "    img_file = random.choice(img_list)\n",
        "    img = cv2.imread(img_file)\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    cv2.imwrite(dataset_dir + 'train/' + os.path.basename(img_file), img)\n",
        "    \n",
        "    if i % 10000 == 0:\n",
        "        print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npMM6xB09Vst",
        "outputId": "dca5abbc-e113-406f-b584-aa31fe1b50c9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# increasing the celeb dataset\n",
        "celeb_files = glob.glob('/content/lama/my_dataset/celeb_train/*')\n",
        "print(f'Number of files {len(celeb_files)}')\n",
        "\n",
        "# gets the max number\n",
        "i = 0\n",
        "while i < (130000 - len(celeb_files)):\n",
        "    img_file = random.choice(celeb_files)\n",
        "    shutil.copy(img_file, '/content/lama/my_dataset/celeb_train/' + str(i+130000) + '.jpg')\n",
        "\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8zd8XFYHZW5",
        "outputId": "768da918-8e99-4b5b-db7e-d48696f56fae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files 129999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "celeb_files = glob.glob('/content/lama/my_dataset/val/*')\n",
        "print(f'Number of files {len(celeb_files)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulsfBdTb8uLZ",
        "outputId": "5b9358ed-2c02-4a8b-db97-94e492f15986"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files 122852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing moving celeba images to training folder\n",
        "celeb_files = glob.glob('/content/lama/celeba-hq-dataset/train_256/*')\n",
        "print(f'Number of files {len(celeb_files)}')\n",
        "shutil.copytree('/content/lama/celeba-hq-dataset/train_256', '/content/lama/my_dataset/celeb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RDdaw2Mi6-kZ",
        "outputId": "0d7c3118-4182-4c94-dd08-cd6708c7c445"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files 26000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/lama/my_dataset/celeb'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting training images to jpg\n",
        "img_list = glob.glob('/content/lama/my_dataset/train/*')\n",
        "for i in range(len(img_list)):\n",
        "    img = cv2.imread(img_list[i])\n",
        "    cv2.imwrite('/content/lama/my_dataset/train_jpg/' + os.path.basename(img_list[i]).replace('.png', '.jpg'), img)"
      ],
      "metadata": {
        "id": "i2sr9nNehgwJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# makes the config file for training\n",
        "!touch my_dataset.yaml\n",
        "!echo \"data_root_dir: $(pwd)/my_dataset/\" >> my_dataset.yaml\n",
        "!echo \"out_root_dir: $(pwd)/experiments/\" >> my_dataset.yaml\n",
        "!echo \"tb_dir: $(pwd)/tb_logs/\" >> my_dataset.yaml\n",
        "!mv my_dataset.yaml ${PWD}/configs/training/location/\n",
        "\n",
        "# change /content/lama/configs/training/trainer/any_gpu_large_ssim_ddp_final.yaml limit_train_batches: 2600 # was 25000"
      ],
      "metadata": {
        "id": "FJbZWmtanNZc"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests\n",
        "# shutil.rmtree('/content/lama/celeba-hq-dataset/data256x256')\n",
        "# shutil.rmtree('/content/lama/celeba-hq-dataset/val_source_256')\n",
        "# shutil.rmtree('/content/lama/celeba-hq-dataset/visual_test_source_256')\n",
        "# have the eval, train, and val\n",
        "\n",
        "!export TORCH_HOME=$(pwd) && export USER='matt' && export PYTHONPATH=. && python3 bin/train.py -cn lama-fourier location=my_dataset data.batch_size=10\n",
        "# !cat ${PWD}/configs/training/data/abl-04-256-mh-dist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUQVVnILn7H1",
        "outputId": "d9577ae4-ff9e-47f8-97ee-a812d0e518d5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\rValidating:  60% 55660/92139 [1:58:43<1:36:13,  6.32it/s]\u001b[A\rEpoch 0:  62% 58280/94739 [2:13:13<1:23:20,  7.29it/s, loss=11, v_num=0]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd77f1518c0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "KeyboardInterrupt\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Saving latest checkpoint...\n",
            "Epoch 0, global step 2598: val_ssim_fid100_f1_total_mean reached 0.00000 (best 0.00000), saving model to \"/content/lama/experiments/matt_2022-02-12_01-32-06_train_lama-fourier_/models/epoch=0-step=2598.ckpt\" as top 5\n",
            "Epoch 0:  62% 58280/94739 [2:13:22<1:23:26,  7.28it/s, loss=11, v_num=0]\n",
            "\n",
            "                                                         \u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vP1BnMXmucG7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}