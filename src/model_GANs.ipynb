{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model_GANs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewYancey/GANime/blob/master/src/model_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfxMXJnq_kzW"
      },
      "source": [
        "# GANime GANs Model\n",
        "This notebook tests the generator network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bouI0_AzCRZy"
      },
      "source": [
        "## Imports and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "885wpFfz2zLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76f32d3-748d-48b5-9abb-7925f8c91645"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "sys.path.append('/content/gdrive/MyDrive/GANime/src')\n",
        "from helper_functions import apply_mask, apply_padding, apply_comp, apply_scale, load_checkpoint, checkpoint\n",
        "from data_loaders import create_dataloaders\n",
        "from networks import Generator, GlobalDiscriminator, weights_init"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw3URZEO3MZm"
      },
      "source": [
        "# network parameters\n",
        "BATCH_SIZE = 15\n",
        "DATASET_SIZE = 100000\n",
        "N_BATCHES = DATASET_SIZE // BATCH_SIZE\n",
        "N_GPU = 1\n",
        "N_WORKERS = 1\n",
        "N_EPOCHS = 100\n",
        "LEARNING_RATE = 0.0002\n",
        "\n",
        "# image\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 455\n",
        "SINGLE_SIDE = 57\n",
        "\n",
        "# tensorboard\n",
        "TRAIN_REFERENCE_INDEX = 200\n",
        "VAL_REFERENCE_INDEX = 100\n",
        "TEST_REFERENCE_INDEX = 20\n",
        "\n",
        "# directories\n",
        "ZIP_PATH_TRAIN = '/content/gdrive/My Drive/GANime/data_out/train.zip'\n",
        "IMG_DIR_TRAIN = '/content/frames/train/'\n",
        "ZIP_PATH_VAL = '/content/gdrive/My Drive/GANime/data_out/validate.zip'\n",
        "IMG_DIR_VAL = '/content/frames/validate/'\n",
        "ZIP_PATH_TEST = '/content/gdrive/My Drive/GANime/data_out/test.zip'\n",
        "IMG_DIR_TEST = '/content/frames/test/'\n",
        "LOG_DIR = '/content/gdrive/My Drive/GANime/data_out/logs/temp2/'\n",
        "PREV_CHECKPOINT = '/content/gdrive/My Drive/GANime/data_out/logs/model_mse/checkpoint.pt' # set to none to not load and create a new log folder\n",
        "# PREV_CHECKPOINT = None # set to none to not load and create a new log folder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT61eB_hRSM4"
      },
      "source": [
        "# unzips images\n",
        "if os.path.exists(IMG_DIR_TRAIN) == False:\n",
        "    shutil.unpack_archive(ZIP_PATH_TRAIN, IMG_DIR_TRAIN, 'zip')\n",
        "    shutil.unpack_archive(ZIP_PATH_VAL, IMG_DIR_VAL, 'zip')\n",
        "    shutil.unpack_archive(ZIP_PATH_TEST, IMG_DIR_TEST, 'zip')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiKyuXpSRBDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63ab14d-617e-4271-ea1f-1b73102f3d60"
      },
      "source": [
        "# sets what device to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and N_GPU > 0) else \"cpu\")\n",
        "print(f'Device: {device}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4NfzEuXCccW"
      },
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DLEwB1B5Y-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8b62c3-c020-414b-880b-f6f078b2912c"
      },
      "source": [
        "dataloader_train, dataloader_val, dataloader_test = create_dataloaders(BATCH_SIZE, N_WORKERS, IMG_DIR_TRAIN, IMG_DIR_VAL, IMG_DIR_TEST, DATASET_SIZE)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset\n",
            "Number of images: 114808\n",
            "Size of dataset: 100000\n",
            "Validation Dataset\n",
            "Number of images: 36734\n",
            "Size of dataset: 36734\n",
            "Testing Dataset\n",
            "Number of images: 2210\n",
            "Size of dataset: 2210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rphdi8N1CiiX"
      },
      "source": [
        "## Networks, Loss Functions, and Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtE6YhY53FrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14b448dc-d071-491c-c34e-e30bf8863590"
      },
      "source": [
        "gen = Generator(N_GPU, IMG_WIDTH, SINGLE_SIDE).to(device)\n",
        "gen.apply(weights_init)\n",
        "global_disc = GlobalDiscriminator(N_GPU).to(device)\n",
        "global_disc.apply(weights_init)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GlobalDiscriminator(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  (conv4): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  (conv5): Conv2d(512, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  (conv6): Conv2d(512, 512, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  (conv7): Conv2d(512, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  (batch64): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batch128): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batch256): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batch512): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNpFXQTnZuh_"
      },
      "source": [
        "loss_bce = nn.BCELoss()\n",
        "loss_mse = nn.MSELoss()\n",
        "optimizer_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.9))\n",
        "optimizer_disc = optim.Adam(global_disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.9))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63H_ZHSZmFfL",
        "outputId": "6f1cac1e-99a8-4a25-9c28-859f11c2ebd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# loads the checkpoint\n",
        "gen, optimizer_gen, batch_counter = load_checkpoint(PREV_CHECKPOINT, LOG_DIR, gen, optimizer_gen)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_lWXZ2i6cbd"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgZ-sLbSvWPv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "outputId": "64fbb76a-8198-4127-f7f6-97d8e2dcacdb"
      },
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "    # gets data for the generator\n",
        "    for i, batch in enumerate(dataloader_train, 0):\n",
        "\n",
        "        #############################\n",
        "        # Discriminator\n",
        "        #############################\n",
        "        global_disc.zero_grad()\n",
        "        output_global_disc = global_disc(batch.to(device))\n",
        "        disc_loss_real = loss_bce(output_global_disc, torch.ones(output_global_disc.shape).cuda())\n",
        "        disc_loss_real.backward()\n",
        "\n",
        "        # apply mask to the images\n",
        "        batch_mask = batch.clone()\n",
        "        batch_mask = apply_mask(batch_mask, IMG_WIDTH, SINGLE_SIDE)\n",
        "\n",
        "        # passes fake images to the Discriminator\n",
        "        gen_output_local, gen_output_global = gen(batch_mask.to(device))\n",
        "        output_global_disc = global_disc(gen_output_global.detach())\n",
        "        disc_loss_fake = loss_bce(output_global_disc, torch.zeros(output_global_disc.shape).to(device))\n",
        "        disc_loss_fake.backward()\n",
        "\n",
        "        # optimized the discriminator\n",
        "        disc_loss = disc_loss_real + disc_loss_fake\n",
        "        optimizer_disc.step()\n",
        "\n",
        "        #############################\n",
        "        # Generater\n",
        "        #############################\n",
        "        gen.zero_grad()\n",
        "        _, gen_output_global = gen(batch_mask.to(device))\n",
        "        # output_global_disc = global_disc()\n",
        "\n",
        "        # combines the sides from the generator with the original 4:3 and calculates the mse loss against the orginal image\n",
        "        gen_output_global = apply_comp(batch.to(device), gen_output_global, IMG_WIDTH, SINGLE_SIDE)\n",
        "        gen_train_loss_mse = loss_mse(gen_output_global, batch.to(device))\n",
        "        \n",
        "        gen_train_loss = gen_train_loss_mse \n",
        "\n",
        "        # error and optimize\n",
        "        gen_train_loss.backward()\n",
        "        optimizer_gen.step()\n",
        "\n",
        "        # prints the status and checkpoints every so often\n",
        "        if i % 10 == 0:\n",
        "            # gets the testing MSE\n",
        "            batch = next(iter(dataloader_val))\n",
        "            batch_mask = batch.clone()\n",
        "            batch_mask = apply_mask(batch_mask, IMG_WIDTH, SINGLE_SIDE)\n",
        "            with torch.no_grad():\n",
        "                _, gen_output_global = gen(batch_mask.to(device))\n",
        "            gen_output_global = apply_comp(batch.to(device), gen_output_global, IMG_WIDTH, SINGLE_SIDE)\n",
        "            val_loss = loss_mse(gen_output_global, batch.to(device))\n",
        "            \n",
        "            print(f'Epoch: {epoch}/{N_EPOCHS}, Batch in Epoch: {i}/{N_BATCHES}, Total Images {batch_counter * BATCH_SIZE}, Gen Train Loss: {gen_train_loss:.4f}, Gen Val Loss: {val_loss:.4f}, Disc Train Loss: {disc_loss:.4f}')\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                checkpoint(batch_counter,\n",
        "                           disc_loss.item(),\n",
        "                           gen_train_loss.item(),\n",
        "                           val_loss.item(),\n",
        "                           LOG_DIR,\n",
        "                           gen,\n",
        "                           optimizer_gen,\n",
        "                           dataloader_train,\n",
        "                           TRAIN_REFERENCE_INDEX,\n",
        "                           dataloader_val,\n",
        "                           VAL_REFERENCE_INDEX,\n",
        "                           dataloader_test,\n",
        "                           TEST_REFERENCE_INDEX,\n",
        "                           IMG_HEIGHT,\n",
        "                           IMG_WIDTH,\n",
        "                           SINGLE_SIDE)\n",
        "\n",
        "        batch_counter += 1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/100, Batch in Epoch: 0/6666, Total Images 3015, Gen Train Loss: 0.0079, Gen Val Loss: 0.0139, Disc Train Loss: 1.5178\n",
            "Saved checkpoint\n",
            "Epoch: 0/100, Batch in Epoch: 10/6666, Total Images 3165, Gen Train Loss: 0.0041, Gen Val Loss: 0.0127, Disc Train Loss: 0.5161\n",
            "Epoch: 0/100, Batch in Epoch: 20/6666, Total Images 3315, Gen Train Loss: 0.0034, Gen Val Loss: 0.0246, Disc Train Loss: 0.1185\n",
            "Epoch: 0/100, Batch in Epoch: 30/6666, Total Images 3465, Gen Train Loss: 0.0137, Gen Val Loss: 0.0202, Disc Train Loss: 0.0567\n",
            "Epoch: 0/100, Batch in Epoch: 40/6666, Total Images 3615, Gen Train Loss: 0.0113, Gen Val Loss: 0.0229, Disc Train Loss: 0.0132\n",
            "Epoch: 0/100, Batch in Epoch: 50/6666, Total Images 3765, Gen Train Loss: 0.0075, Gen Val Loss: 0.0219, Disc Train Loss: 0.0084\n",
            "Epoch: 0/100, Batch in Epoch: 60/6666, Total Images 3915, Gen Train Loss: 0.0096, Gen Val Loss: 0.0296, Disc Train Loss: 0.0253\n",
            "Epoch: 0/100, Batch in Epoch: 70/6666, Total Images 4065, Gen Train Loss: 0.0099, Gen Val Loss: 0.0196, Disc Train Loss: 0.0037\n",
            "Epoch: 0/100, Batch in Epoch: 80/6666, Total Images 4215, Gen Train Loss: 0.0107, Gen Val Loss: 0.0134, Disc Train Loss: 0.0105\n",
            "Epoch: 0/100, Batch in Epoch: 90/6666, Total Images 4365, Gen Train Loss: 0.0074, Gen Val Loss: 0.0250, Disc Train Loss: 0.0007\n",
            "Epoch: 0/100, Batch in Epoch: 100/6666, Total Images 4515, Gen Train Loss: 0.0080, Gen Val Loss: 0.0270, Disc Train Loss: 0.0038\n",
            "Saved checkpoint\n",
            "Epoch: 0/100, Batch in Epoch: 110/6666, Total Images 4665, Gen Train Loss: 0.0041, Gen Val Loss: 0.0260, Disc Train Loss: 0.0018\n",
            "Epoch: 0/100, Batch in Epoch: 120/6666, Total Images 4815, Gen Train Loss: 0.0096, Gen Val Loss: 0.0177, Disc Train Loss: 0.0017\n",
            "Epoch: 0/100, Batch in Epoch: 130/6666, Total Images 4965, Gen Train Loss: 0.0106, Gen Val Loss: 0.0084, Disc Train Loss: 0.0019\n",
            "Epoch: 0/100, Batch in Epoch: 140/6666, Total Images 5115, Gen Train Loss: 0.0075, Gen Val Loss: 0.0141, Disc Train Loss: 0.0010\n",
            "Epoch: 0/100, Batch in Epoch: 150/6666, Total Images 5265, Gen Train Loss: 0.0101, Gen Val Loss: 0.0360, Disc Train Loss: 0.0002\n",
            "Epoch: 0/100, Batch in Epoch: 160/6666, Total Images 5415, Gen Train Loss: 0.0081, Gen Val Loss: 0.0195, Disc Train Loss: 0.0002\n",
            "Epoch: 0/100, Batch in Epoch: 170/6666, Total Images 5565, Gen Train Loss: 0.0050, Gen Val Loss: 0.0179, Disc Train Loss: 0.0002\n",
            "Epoch: 0/100, Batch in Epoch: 180/6666, Total Images 5715, Gen Train Loss: 0.0054, Gen Val Loss: 0.0272, Disc Train Loss: 0.0114\n",
            "Epoch: 0/100, Batch in Epoch: 190/6666, Total Images 5865, Gen Train Loss: 0.0089, Gen Val Loss: 0.0245, Disc Train Loss: 0.0002\n",
            "Epoch: 0/100, Batch in Epoch: 200/6666, Total Images 6015, Gen Train Loss: 0.0113, Gen Val Loss: 0.0131, Disc Train Loss: 0.0003\n",
            "Saved checkpoint\n",
            "Epoch: 0/100, Batch in Epoch: 210/6666, Total Images 6165, Gen Train Loss: 0.0047, Gen Val Loss: 0.0166, Disc Train Loss: 0.0000\n",
            "Epoch: 0/100, Batch in Epoch: 220/6666, Total Images 6315, Gen Train Loss: 0.0067, Gen Val Loss: 0.0271, Disc Train Loss: 0.0004\n",
            "Epoch: 0/100, Batch in Epoch: 230/6666, Total Images 6465, Gen Train Loss: 0.0043, Gen Val Loss: 0.0189, Disc Train Loss: 0.0000\n",
            "Epoch: 0/100, Batch in Epoch: 240/6666, Total Images 6615, Gen Train Loss: 0.0085, Gen Val Loss: 0.0112, Disc Train Loss: 0.0007\n",
            "Epoch: 0/100, Batch in Epoch: 250/6666, Total Images 6765, Gen Train Loss: 0.0084, Gen Val Loss: 0.0114, Disc Train Loss: 0.0001\n",
            "Epoch: 0/100, Batch in Epoch: 260/6666, Total Images 6915, Gen Train Loss: 0.0073, Gen Val Loss: 0.0101, Disc Train Loss: 0.0001\n",
            "Epoch: 0/100, Batch in Epoch: 270/6666, Total Images 7065, Gen Train Loss: 0.0090, Gen Val Loss: 0.0188, Disc Train Loss: 0.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a6d1c778d028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# combines the sides from the generator with the original 4:3 and calculates the mse loss against the orginal image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mgen_output_global\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_comp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_output_global\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSINGLE_SIDE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mgen_train_loss_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_output_global\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}